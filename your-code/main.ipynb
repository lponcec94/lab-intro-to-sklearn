{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Explore the Scikit-Learn Datasets\n",
    "\n",
    "Before starting to work on our own datasets, let's first explore the datasets that are included in this Python library. These datasets have been cleaned and formatted for use in ML algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the diabetes dataset. Do this in the cell below by importing the datasets and then loading the dataset  to the `diabetes` variable using the `load_diabetes()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore this variable by looking at the different attributes. Do this by looking at the `keys()` of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to read the description of the dataset. Print the description in the cell below using the `DESCR` attribute of the `diabetes` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(diabetes['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the variables in this dataset according to the description? List them in the markdown cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter your answer here:\n",
    "    - age     age in years\n",
    "    - sex\n",
    "    - bmi     body mass index\n",
    "    - bp      average blood pressure\n",
    "    - s1      tc, total serum cholesterol\n",
    "    - s2      ldl, low-density lipoproteins\n",
    "    - s3      hdl, high-density lipoproteins\n",
    "    - s4      tch, total cholesterol / HDL\n",
    "    - s5      ltg, possibly log of serum triglycerides level\n",
    "    - s6      glu, blood sugar level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now explore the data. Scikit-learn typically takes in 2D numpy arrays as input (though pandas dataframes are also accepted). In the cell below find the shape of the numpy array contained in the data portion of the diabetes variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(diabetes['data'])\n",
    "# diabetes['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Perform Supervised Learning on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data has already been split to predictor and response variables. The response variable is in the `target` portion of the variable. \n",
    "\n",
    "Given this information, let's apply what we have previously learned about linear regression and apply the algorithm to the diabetes dataset. In the cell below, import the linear regression class from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model in the variable `diabetes_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, fit the model and print the intercept and coefficients of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.1334841628965\n",
      "[ -10.01219782 -239.81908937  519.83978679  324.39042769 -792.18416163\n",
      "  476.74583782  101.04457032  177.06417623  751.27932109   67.62538639]\n"
     ]
    }
   ],
   "source": [
    "diabetes_model.fit(diabetes['data'], diabetes['target'])\n",
    "print(diabetes_model.intercept_)\n",
    "print(diabetes_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 1 - Conduct a Hypothesis Test on the Model\n",
    "\n",
    "Once we have generated a linear model, we can test each coefficient using a t-test to see whether the confidence interval for the variable contains zero. We can also perform an overall F test to check whether at least one coefficient is significantly different from zero. \n",
    "\n",
    "Refer to the resource in this [link](https://onlinecourses.science.psu.edu/stat501/node/297/) for more details and perform the t-tests for the model above. Additionally, interpret the results and list coefficients are significantly different from zero.\n",
    "\n",
    "\n",
    "Hint: use the statsmodels package.\n",
    "\n",
    "Your result should look similar to this:\n",
    "\n",
    "![ols](../ols-results.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats import diagnostic\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.518\n",
      "Model:                            OLS   Adj. R-squared:                  0.507\n",
      "Method:                 Least Squares   F-statistic:                     46.27\n",
      "Date:                Wed, 18 May 2022   Prob (F-statistic):           3.83e-62\n",
      "Time:                        13:14:31   Log-Likelihood:                -2386.0\n",
      "No. Observations:                 442   AIC:                             4794.\n",
      "Df Residuals:                     431   BIC:                             4839.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        152.1335      2.576     59.061      0.000     147.071     157.196\n",
      "x1           -10.0122     59.749     -0.168      0.867    -127.448     107.424\n",
      "x2          -239.8191     61.222     -3.917      0.000    -360.151    -119.488\n",
      "x3           519.8398     66.534      7.813      0.000     389.069     650.610\n",
      "x4           324.3904     65.422      4.958      0.000     195.805     452.976\n",
      "x5          -792.1842    416.684     -1.901      0.058   -1611.169      26.801\n",
      "x6           476.7458    339.035      1.406      0.160    -189.621    1143.113\n",
      "x7           101.0446    212.533      0.475      0.635    -316.685     518.774\n",
      "x8           177.0642    161.476      1.097      0.273    -140.313     494.442\n",
      "x9           751.2793    171.902      4.370      0.000     413.409    1089.150\n",
      "x10           67.6254     65.984      1.025      0.306     -62.065     197.316\n",
      "==============================================================================\n",
      "Omnibus:                        1.506   Durbin-Watson:                   2.029\n",
      "Prob(Omnibus):                  0.471   Jarque-Bera (JB):                1.404\n",
      "Skew:                           0.017   Prob(JB):                        0.496\n",
      "Kurtosis:                       2.726   Cond. No.                         227.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[206.11706979  68.07234761 176.88406035 166.91796559 128.45984241\n",
      " 106.34908972  73.89417947 118.85378669 158.81033076 213.58408893\n",
      "  97.07853583  95.1016223  115.06673301 164.67605023 103.07517946\n",
      " 177.17236996 211.75953205 182.84424343 147.99987605 124.01702527\n",
      " 120.33094632  85.80377894 113.11286302 252.44934852 165.48821056\n",
      " 147.72187623  97.12824075 179.09342974 129.05497324 184.78138552\n",
      " 158.71515746  69.47588393 261.50255826 112.81897436  78.37194762\n",
      "  87.66624129 207.92460213 157.87686037 240.84370686 136.93372685\n",
      " 153.48187659  74.15703284 145.63105805  77.8280105  221.0786645\n",
      " 125.22224022 142.60147066 109.4926324   73.14037106 189.87368742\n",
      " 157.93636782 169.55816531 134.18186217 157.72356219 139.1077439\n",
      "  72.73252701 207.8289973   80.10834588 104.08562488 134.57807971\n",
      " 114.23779529 180.67760064  61.12644508  98.7215441  113.79626149\n",
      " 189.96141244 148.98263155 124.33457266 114.83969622 122.00224605\n",
      "  73.91315064 236.70948329 142.31366526 124.51427625 150.84273716\n",
      " 127.75408702 191.16674356  77.05921006 166.82129568  91.00741773\n",
      " 174.75026808 122.83488194  63.27214662 151.99895968  53.73407848\n",
      " 166.00134469  42.65030679 153.04135861  80.54493791 106.9048058\n",
      "  79.94239571 187.1634566  192.60115666  61.07125918 107.40466928\n",
      " 125.04038427 207.72180472 214.21749964 123.47505642 139.16396617\n",
      " 168.21035724 106.9267784  150.64502809 157.92231541 152.75856279\n",
      " 116.22255529  73.03090141 155.66898717 230.14278537 143.50191007\n",
      "  38.0947967  121.860737   152.79569851 207.99651918 291.23082717\n",
      " 189.17431487 214.02871163 235.18090808 165.3872774  151.25000032\n",
      " 156.57626783 200.44154589 219.35211772 174.79049427 169.23161767\n",
      " 187.8719893   57.49473392 108.55110499  92.68518048 210.87365701\n",
      " 245.47433558  69.84529943 113.0351432   68.42945176 141.69628649\n",
      " 239.46177949  58.3802079  235.47268158 254.91986281 253.31042713\n",
      " 155.50813249 230.55904185 170.44063216 117.99200943 178.55548636\n",
      " 240.07155813 190.3398776  228.66100769 114.24162642 178.36570405\n",
      " 209.09273631 144.85567253 200.65791056 121.34184881 150.50918174\n",
      " 199.02165018 146.2806806  124.02443772  85.26036769 235.16536625\n",
      "  82.17255475 231.29266191 144.36634395 197.04778326 146.99720377\n",
      "  77.18477545  59.3728572  262.67891084 225.12578458 220.20506312\n",
      "  46.59691745  88.1040833  221.77623752  97.24900614 164.48869956\n",
      " 119.90114263 157.79986195 223.08505437  99.5885471  165.84341641\n",
      " 179.47571002  89.83382843 171.82492808 158.36337775 201.47857482\n",
      " 186.39202728 197.47094269  66.57241937 154.59826802 116.18638034\n",
      " 195.92074021 128.04740268  91.20285628 140.56975398 155.23013996\n",
      " 169.70207476  98.75498537 190.1453107  142.5193942  177.26966106\n",
      "  95.31403505  69.0645889  164.16669511 198.06460718 178.26228169\n",
      " 228.58801706 160.67275473 212.28682319 222.48172067 172.85184399\n",
      " 125.27697688 174.7240982  152.38282657  98.58485669  99.73695497\n",
      " 262.29658755 223.73784832 221.3425256  133.61497308 145.42593933\n",
      "  53.04259372 141.81807792 153.68369915 125.21948824  77.25091512\n",
      " 230.26311068  78.90849563 105.20931175 117.99633487  99.06361032\n",
      " 166.55382825 159.34391027 158.27612808 143.05658763 231.55938678\n",
      " 176.64144413 187.23572317  65.38504165 190.66078824 179.74973878\n",
      " 234.91022512 119.15540438  85.63464409 100.85860205 140.4174259\n",
      " 101.83836332 120.66138775  83.06599161 234.58754656 245.16192142\n",
      " 263.26766492 274.87431887 180.67699732 203.05474761 254.21769367\n",
      " 118.44122343 268.44988948 104.83643442 115.87172349 140.45788952\n",
      "  58.46850453 129.83264097 263.78452618  45.01240356 123.28697604\n",
      " 131.08314499  34.89018315 138.35659686 244.30370588  89.95612306\n",
      " 192.07094588 164.32674962 147.74783541 191.89381753 176.44296313\n",
      " 158.34707354 189.19183226 116.58275843 111.44622859 117.45262547\n",
      " 165.79457547  97.80241129 139.54389024  84.17453643 159.9389204\n",
      " 202.4011919   80.48200416 146.64621068  79.05274311 191.33759392\n",
      " 220.67545196 203.75145711  92.87093594 179.15570241  81.80126162\n",
      " 152.82706623  76.79700486  97.79712384 106.83424483 123.83477117\n",
      " 218.13375502 126.02077447 206.76300555 230.57976636 122.0628518\n",
      " 135.67694517 126.36969016 148.49621551  88.07082258 138.95595037\n",
      " 203.86570118 172.55362727 122.95773416 213.92445645 174.88857841\n",
      " 110.07169487 198.36767241 173.24601643 162.64946177 193.31777358\n",
      " 191.53802295 284.13478714 279.30688474 216.0070265  210.08517801\n",
      " 216.22213925 157.01489819 224.06561179 189.05840605 103.56829281\n",
      " 178.70442926 111.81492124 290.99913121 182.64959461  79.33602602\n",
      "  86.33287509 249.15238929 174.51439576 122.10645431 146.27099383\n",
      " 170.6555544  183.50018707 163.36970989 157.03563376 144.42617093\n",
      " 125.30179325 177.50072942 104.57821235 132.1746674   95.06145678\n",
      " 249.9007786   86.24033937  62.00077469 156.81087903 192.3231713\n",
      " 133.85292727  93.67456315 202.49458467  52.53953733 174.82926235\n",
      " 196.9141296  118.06646574 235.3011088  165.09286707 160.41863314\n",
      " 162.37831419 254.05718804 257.23616403 197.50578991 184.06609359\n",
      "  58.62043851 194.3950396  110.77475548 142.20916765 128.82725506\n",
      " 180.12844365 211.26415225 169.59711427 164.34167693 136.2363478\n",
      " 174.50905908  74.67649224 246.29542114 114.14131338 111.54358708\n",
      " 140.02313284 109.99647408  91.37269237 163.01389345  75.16389857\n",
      " 254.05755095  53.47055785  98.48060512 100.66268306 258.58885744\n",
      " 170.67482041  61.91866052 182.3042492  171.26913027 189.19307553\n",
      " 187.18384852  87.12032949 148.37816611 251.35898288 199.69712357\n",
      " 283.63722409  50.85577124 172.14848891 204.06179478 174.16816194\n",
      " 157.93027543 150.50201654 232.9761832  121.5808709  164.54891787\n",
      " 172.67742636 226.78005938 149.46967223  99.14026374  80.43680779\n",
      " 140.15557121 191.90593837 199.27952034 153.63210613 171.80130949\n",
      " 112.11314588 162.60650576 129.8448476  258.02898298 100.70869427\n",
      " 115.87611124 122.53790409 218.17749233  60.94590955 131.09513588\n",
      " 119.48417359  52.60848094 193.01802803 101.05169913 121.22505534\n",
      " 211.8588945   53.44819015]\n"
     ]
    }
   ],
   "source": [
    "X = sm.add_constant(diabetes.data)\n",
    "Y = diabetes.target\n",
    "\n",
    "modelo = sm.OLS(Y, X).fit()\n",
    "prediction = modelo.predict()\n",
    "print(modelo.summary())\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Peform Supervised Learning on a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have looked at data that has been formatted for scikit-learn, let's look at data that we will need to format ourselves.\n",
    "\n",
    "In the next cell, load the `auto-mpg.csv` file included in this folder and assign it to a variable called `auto`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv('../auto-mpg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 5 rows using the `head()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"chevrolet chevelle malibu\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"buick skylark 320\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"plymouth satellite\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"amc rebel sst\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"ford torino\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horse_power  weight  acceleration  \\\n",
       "0  18.0          8         307.0        130.0    3504          12.0   \n",
       "1  15.0          8         350.0        165.0    3693          11.5   \n",
       "2  18.0          8         318.0        150.0    3436          11.0   \n",
       "3  16.0          8         304.0        150.0    3433          12.0   \n",
       "4  17.0          8         302.0        140.0    3449          10.5   \n",
       "\n",
       "   model_year                       car_name  \n",
       "0          70  \\t\"chevrolet chevelle malibu\"  \n",
       "1          70          \\t\"buick skylark 320\"  \n",
       "2          70         \\t\"plymouth satellite\"  \n",
       "3          70              \\t\"amc rebel sst\"  \n",
       "4          70                \\t\"ford torino\"  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the data to ensure that all numeric columns are correctly detected as such by pandas. If a column is misclassified as object, coerce it to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horse_power   392 non-null    float64\n",
      " 4   weight        398 non-null    int64  \n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model_year    398 non-null    int64  \n",
      " 7   car_name      398 non-null    object \n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 25.0+ KB\n"
     ]
    }
   ],
   "source": [
    "auto.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the newest model year and the oldest model year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(auto.model_year.max())\n",
    "print(auto.model_year.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dataset for missing values and remove all rows containing at least one missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the frequency table for the `cylinders` column using the `value_counts()` function. How many possible values of cylinders are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    199\n",
       "8    103\n",
       "6     83\n",
       "3      4\n",
       "5      3\n",
       "Name: cylinders, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.cylinders.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to generate a linear regression model that will predict mpg. To do this, first drop the `car_name` column since it does not contain any quantitative data. Next separate the dataframe to predictor and response variables. Separate those into test and training data with 80% of the data in the training set and the remainder in the test set. \n",
    "\n",
    "Assign the predictor and response training data to `X_train` and `y_train` respectively. Similarly, assign the predictor and response test data to `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.drop('car_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = auto.drop('mpg', axis=1)\n",
    "y = auto['mpg']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((313, 6), (79, 6), (313,), (79,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will the dataset that we processed and peform linear regression on this data to predict the mpg for each vehicle. Initialize the model in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, fit the model in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8340546600899306"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model.fit(X_train, y_train)\n",
    "auto_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Evaluate the Model\n",
    "\n",
    "the r squared score of a model tells us how much variation is explained by the model. In a typical dataset, most observations differ from the mean. When we create a model, we are trying to generate an equation that will tell us by how much each observation will differ from the mean. Obviously, the vast majority of models are not perfect. They can only predict some of the variation from the mean but not all of it. We attribute the rest of the difference between the actual value and the mean to random error. We would like random error to explain the as little as possible of the variation. This is why the r squared score is an important metric.\n",
    "\n",
    "In the next cell, compute the r squared score of the model. Do this by first computing the predicted values and assign them to `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = auto_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our next step is to evaluate the model using the test data. We would like to ensure that our model is not overfitting the data. This means that our model will not be able to generalize well outside of the training data.\n",
    "\n",
    "In the cell below, use the model to generate the predicted values for the training data and assign them to `y_test_pred`. Compute the r squared score for the test data by comparing the oberserved `y_test` data and the predicted `y_test_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Improve the Model Fit\n",
    "\n",
    "While the most common way to improve the fit of a model is by using regularization, there are other simpler ways to improve model fit. The first is to create a simpler model. The second is to increase the train sample size.\n",
    "\n",
    "Let us start with the easier option and increase our train sample size to 90% of the data. Create a new test train split and name the new predictors and response variables `X_train09`, `X_test09`, `y_train09`, `y_test09`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train09, X_test09, y_train09, y_test09 = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a new model. Name this model `auto_model09`. Fit the model to the new sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model09 = LinearRegression()\n",
    "\n",
    "auto_model09.fit(X_train09, y_train09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predicted values and r squared score for our new model and new sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred09 = auto_model09.predict(X_test09)\n",
    "r2_09 = r2_score(y_test09, y_pred09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the r squared score for the smaller test set. Is there an improvement in the test r squared?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6744338142742181"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 2 - Backward Elimination \n",
    "\n",
    "The main way to produce a simpler linear regression model is to reduce the number of variables used in the model. In scikit-learn, we can do this by using recursive feature elimination. You can read more about RFE [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html).\n",
    "\n",
    "In the next cell, we will import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the documentation and initialize an RFE model using the `auto_model` linear regression model. Set `n_features_to_select=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "selecto = RFE(auto_model, n_features_to_select=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and print the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cylinders' 'displacement' 'horse_power' 'weight' 'acceleration'\n",
      " 'model_year']\n",
      "[1 2 4 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "selecto.fit(X, y)\n",
    "print(selecto.feature_names_in_)\n",
    "print(selecto.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance is ranked from most important (1) to least important (4). Generate a model with the three most important features. The features correspond to variable names. For example, feature 1 is `cylinders` and feature 2 is `displacement`.\n",
    "\n",
    "Perform a test-train split on this reduced column data and call the split data `X_train_reduced`, `X_test_reduced`, `y_test_reduced`, `y_train_reduced`. Use an 80% split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = auto[['cylinders', 'acceleration', 'model_year']]\n",
    "y_reduced = auto['mpg']\n",
    "\n",
    "X_train_reduced, X_test_reduced, y_train_reduced, y_test_reduced = train_test_split(\n",
    "    X_reduced, \n",
    "    y_reduced, \n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a new model called `auto_model_reduced` and fit this model. Then proceed to compute the r squared score for the model. Did this cause an improvement in the r squared score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model_reduced = LinearRegression()\n",
    "auto_model_reduced.fit(X_train_reduced, y_train_reduced)\n",
    "y_pred_reduced = auto_model_reduced.predict(X_test_reduced)\n",
    "r2_reduced = r2_score(y_test_reduced, y_pred_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6744338142742181, 0.8885401480052811, 0.7800549121732743)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2, r2_09, r2_reduced"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7579aee364a2e290dfc6a620616239004625e0c1356cc42c7bb47894a11803af"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
